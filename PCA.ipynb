{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40b5e61",
   "metadata": {},
   "source": [
    "# Principle Component Analysis\n",
    "\n",
    "## 1. Einleitung\n",
    "Dieses Jupyter Notebook stellt eine Ergänzung der wissenschaftlichen Arbeit über die Principle Component Analysis dar. Der prinzipielle Aufbau des Notebooks ist daher gleich mit dem der Arbeit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab40ff0",
   "metadata": {},
   "source": [
    "## 2. Mathematische Grundlagen \n",
    "Nachfolgend wird der Unterschied zwischen einer geringen und einer hohen Varainz veranschaulicht und dessen Berechnung eingeführt.\n",
    "\n",
    "### 2.1 Standardabweichung und Varianz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fceeb467",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Erstellen von Daten\n",
    "X1 = np.arange(-1, 1.1, 0.1)\n",
    "X2 = np.arange(-10, 11, 1)\n",
    "Y1 = np.repeat(-1,len(X1))\n",
    "Y2 = np.repeat(1,len(X2))\n",
    "\n",
    "#Plotten von Daten\n",
    "plt.plot(Y1, X1, 'x')\n",
    "plt.plot(Y2, X2, 'x')\n",
    "\n",
    "#Formatierung des Plots\n",
    "plt.grid()\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-12, 12)\n",
    "\n",
    "#Speichern des Plots\n",
    "plt.savefig('Figures/Std_Var.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b3c7de",
   "metadata": {},
   "source": [
    "### 2.2 Eigenwerte und Eigenvektoren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe6103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erstellen einer Matix\n",
    "\n",
    "\n",
    "#Berechnung der Eigenwerte und Eigenvektoren\n",
    "\n",
    "\n",
    "#Zeigen, dass Eigenvektoren rechtwicklig zueinader sind\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c220d95a",
   "metadata": {},
   "source": [
    "## 3. Durchführung einer PCA\n",
    "\n",
    "### 3.1 Standardisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8127384",
   "metadata": {},
   "source": [
    "Zuerst werden einige zufällige Daten generiert. Es werden 100 Beispiele mit je 3 Merkmalen generiert.\n",
    "Daraufhin werden die Merkmale standardisiert indem der Mittelwert subtrahiert und durch die Standardabweichung geteilt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d614e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(20, 5)\n",
    "X = (X - X.mean()) / X.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc46f85",
   "metadata": {},
   "source": [
    "### 3.2 Berechnung der Kovarianzmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7eae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.cov(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d7570",
   "metadata": {},
   "source": [
    "### 3.3 Berechnen der Eigenvektoren und Eigenwerte der Kovarianzmatrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c2add",
   "metadata": {},
   "source": [
    "Die Eigenwerte und Eigenvektoren werden berechnet und danach in absteigender Reihenfolge sortiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1948b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(C)\n",
    "eigenvalues, eigenvectors = zip(*sorted(zip(eigenvalues, eigenvectors), key=lambda x: x[0], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05175e7a",
   "metadata": {},
   "source": [
    "### 3.4 Bilden eines Feature Vektors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2deb32f",
   "metadata": {},
   "source": [
    "Zur Durchführung der PCA muss die Anzahl der Komponenten angegeben werden die behalten werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2182c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "feature_vector_matrix = eigenvectors[:n_components]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1fba87",
   "metadata": {},
   "source": [
    "### 3.5 Umformen der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f7b88d",
   "metadata": {},
   "source": [
    "Die Matrix aus den Feature Vektoren wird dann umgeformt auf die Achsen der neuen Hauptkomponenten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79756770",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_converted = X.dot(feature_vector_matrix)\n",
    "print(X_pca_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = np.dot(X, eigenvectors)\n",
    "print(\"Transformed data \", pca_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ab8ee",
   "metadata": {},
   "source": [
    "### 5.1 Dimensionsreduktion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8448db8",
   "metadata": {},
   "source": [
    "Im folgenden wird ein bekanntes Beispiel einer Gesichtserkennung mit der ORL Datenbank das je 10 Bilder von 40 verschiedenen Personen beinhaltet bis zur Anwendung der PCA gezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8be362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Read face image from zip file on the fly\n",
    "faces = {}\n",
    "with zipfile.ZipFile(\"C:/Users/num4abt/Downloads/archive1.zip\") as facezip:\n",
    "    for filename in facezip.namelist():\n",
    "        if not filename.endswith(\".pgm\"):\n",
    "            continue # not a face picture\n",
    "        with facezip.open(filename) as image:\n",
    "            # If we extracted files from zip, we can use cv2.imread(filename) instead\n",
    "            faces[filename] = cv2.imdecode(np.frombuffer(image.read(), np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Show sample faces using matplotlib\n",
    "fig, axes = plt.subplots(4,4,sharex=True,sharey=True,figsize=(8,10))\n",
    "faceimages = list(faces.values())[-16:] # take last 16 images\n",
    "for i in range(16):\n",
    "    axes[i%4][i//4].imshow(faceimages[i], cmap=\"gray\")\n",
    "print(\"Showing sample faces\")\n",
    "plt.show()\n",
    "\n",
    "# Print some details\n",
    "faceshape = list(faces.values())[0].shape\n",
    "print(\"Face image shape:\", faceshape)\n",
    "\n",
    "classes = set(filename.split(\"/\")[0] for filename in faces.keys())\n",
    "print(\"Number of classes:\", len(classes))\n",
    "print(\"Number of images:\", len(faces))\n",
    "\n",
    "# Take classes 1-39 for eigenfaces, keep entire class 40 and\n",
    "# image 10 of class 39 as out-of-sample test\n",
    "facematrix = []\n",
    "facelabel = []\n",
    "for key,val in faces.items():\n",
    "    if key.startswith(\"s40/\"):\n",
    "        continue # this is our test set\n",
    "    if key == \"s39/10.pgm\":\n",
    "        continue # this is our test set\n",
    "    facematrix.append(val.flatten())\n",
    "    facelabel.append(key.split(\"/\")[0])\n",
    "\n",
    "# Create a NxM matrix with N images and M pixels per image\n",
    "facematrix = np.array(facematrix)\n",
    "\n",
    "# Apply PCA and take first K principal components as eigenfaces\n",
    "pca = PCA().fit(facematrix)\n",
    "\n",
    "n_components = 50\n",
    "eigenfaces = pca.components_[:n_components]\n",
    "\n",
    "# Show the first 16 eigenfaces\n",
    "#fig, axes = plt.subplots(4,4,sharex=True,sharey=True,figsize=(8,10))\n",
    "#for i in range(16):\n",
    "#    axes[i%4][i//4].imshow(eigenfaces[i].reshape(faceshape), cmap=\"gray\")\n",
    "#print(\"Showing the eigenfaces\")\n",
    "#plt.show()\n",
    "\n",
    "# Generate weights as a KxN matrix where K is the number of eigenfaces and N the number of samples\n",
    "weights = eigenfaces @ (facematrix - pca.mean_).T\n",
    "print(\"Shape of the weight matrix:\", weights.shape)\n",
    "\n",
    "# Test on out-of-sample image of existing class\n",
    "query = faces[\"s39/10.pgm\"].reshape(1,-1)\n",
    "query_weight = eigenfaces @ (query - pca.mean_).T\n",
    "euclidean_distance = np.linalg.norm(weights - query_weight, axis=0)\n",
    "best_match = np.argmin(euclidean_distance)\n",
    "print(\"Best match %s with Euclidean distance %f\" % (facelabel[best_match], euclidean_distance[best_match]))\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1,2,sharex=True,sharey=True,figsize=(8,6))\n",
    "axes[0].imshow(query.reshape(faceshape), cmap=\"gray\")\n",
    "axes[0].set_title(\"Query\")\n",
    "axes[1].imshow(facematrix[best_match].reshape(faceshape), cmap=\"gray\")\n",
    "axes[1].set_title(\"Best match\")\n",
    "plt.show()\n",
    "\n",
    "# Test on out-of-sample image of new class\n",
    "query = faces[\"s40/1.pgm\"].reshape(1,-1)\n",
    "query_weight = eigenfaces @ (query - pca.mean_).T\n",
    "euclidean_distance = np.linalg.norm(weights - query_weight, axis=0)\n",
    "best_match = np.argmin(euclidean_distance)\n",
    "print(\"Best match %s with Euclidean distance %f\" % (facelabel[best_match], euclidean_distance[best_match]))\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1,2,sharex=True,sharey=True,figsize=(8,6))\n",
    "axes[0].imshow(query.reshape(faceshape), cmap=\"gray\")\n",
    "axes[0].set_title(\"Query\")\n",
    "axes[1].imshow(facematrix[best_match].reshape(faceshape), cmap=\"gray\")\n",
    "axes[1].set_title(\"Best match\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61641070",
   "metadata": {},
   "source": [
    "### 5.2 PCA zur Unterstützung beim Clustering\n",
    "\n",
    "Beispiel einfügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef569cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775971d1",
   "metadata": {},
   "source": [
    "### 5.3 PCA zur Bildkompression\n",
    "\n",
    "In diesem Beispiel wird gezeigt, wie mehere Bilder mithilfe der PCA komprimiert werden können. Dazu werden die Bilder aus Abschnitt 5.1 wiederverwendet. Unkomprimiert haben diese eine Größe von ___ Byte.\n",
    "Zur Kompression der Bilder werden die 400 Bilder \"übereinander\" gelegt und ein Vektor für jeden Pixel über alle Bilder gebildet. Da die Bilder dieses Datensatzes 112 mal 92 Pixel besitzen, ergeben sich 10304 Vektoren mit je 400 Elementen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bilder aus Datei laden\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc923b",
   "metadata": {},
   "source": [
    "Im nächsten Schritt wird die PCA mit diesen Vekotren durchgeführt. Daher ergeben sich 400 Eigenwerte und Eigenvektoren. Der Beitrag der Hauptkomponeten ist anschließend in einer Grafik Visualisiert. Anhand dieser wird beschlossen auschließlich die Informationen der __ Hauptkomponenten zu verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA Bilder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f74ec8",
   "metadata": {},
   "source": [
    "Nun sind die Orginalen Bilder in den neuen Raum zu transformieren. Dies wird exemplarisch für ein Bild gemacht. Da nicht alle Hauptkomponenten verwendet werden, geht bei diesem Schritt Information verlohren. Dies ist im Vergleich zwischen der Orginal-Bild und dem Komprimierten Bild zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca89e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umformen eines Bilds & vergleich der Bilder\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
